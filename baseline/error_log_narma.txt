Getting NARMA data...
seed: 2027
x_train.shape:  torch.Size([160, 10, 1])
x_val.shape:  torch.Size([34, 10, 1])
x_test.shape:  torch.Size([35, 10, 1])
y.shape: torch.Size([229, 1])
Show the parameters in QLSTM.
Parameter name: cell.input_gate.weights
Parameter shape: torch.Size([5, 6])
Parameter name: cell.forget_gate.weights
Parameter shape: torch.Size([5, 6])
Parameter name: cell.cell_gate.weights
Parameter shape: torch.Size([5, 6])
Parameter name: cell.output_gate.weights
Parameter shape: torch.Size([5, 6])
Parameter name: cell.output_post_processing.weight
Parameter shape: torch.Size([1, 5])
Parameter name: cell.output_post_processing.bias
Parameter shape: torch.Size([1])
Epoch 0 finished in 233.03 seconds
TRAIN LOSS at 0-th epoch: 0.1206800689654968
VAL LOSS at 0-th epoch: 0.095254693541241
TEST LOSS at 0-th epoch: 0.07558646529366964
Epoch 1 finished in 234.65 seconds
TRAIN LOSS at 1-th epoch: 0.11034772729144068
VAL LOSS at 1-th epoch: 0.09483182902928919
TEST LOSS at 1-th epoch: 0.07584634531374333
Epoch 2 finished in 237.26 seconds
TRAIN LOSS at 2-th epoch: 0.10785113761138235
VAL LOSS at 2-th epoch: 0.0945283401143611
TEST LOSS at 2-th epoch: 0.07714538202956889
Epoch 3 finished in 252.11 seconds
TRAIN LOSS at 3-th epoch: 0.10370298721900666
VAL LOSS at 3-th epoch: 0.0933527281080211
TEST LOSS at 3-th epoch: 0.07759948211583848
Epoch 4 finished in 259.28 seconds
TRAIN LOSS at 4-th epoch: 0.09563579351307469
VAL LOSS at 4-th epoch: 0.09276211037928146
TEST LOSS at 4-th epoch: 0.07845233785148716
Epoch 5 finished in 264.64 seconds
TRAIN LOSS at 5-th epoch: 0.0865410699763843
VAL LOSS at 5-th epoch: 0.09167216134589579
TEST LOSS at 5-th epoch: 0.07579382977299998
Epoch 6 finished in 272.69 seconds
TRAIN LOSS at 6-th epoch: 0.08023082967462937
VAL LOSS at 6-th epoch: 0.09053967797420369
TEST LOSS at 6-th epoch: 0.0718424141342657
Epoch 7 finished in 268.23 seconds
TRAIN LOSS at 7-th epoch: 0.07694203208384023
VAL LOSS at 7-th epoch: 0.09020922730327216
TEST LOSS at 7-th epoch: 0.0696061745840563
Epoch 8 finished in 272.14 seconds
TRAIN LOSS at 8-th epoch: 0.07532514763658221
VAL LOSS at 8-th epoch: 0.09017591134354089
TEST LOSS at 8-th epoch: 0.06852472690608838
Epoch 9 finished in 277.77 seconds
TRAIN LOSS at 9-th epoch: 0.07443306727049792
VAL LOSS at 9-th epoch: 0.09017194605404762
TEST LOSS at 9-th epoch: 0.06792065936531498
Epoch 10 finished in 279.79 seconds
TRAIN LOSS at 10-th epoch: 0.07386420456004218
VAL LOSS at 10-th epoch: 0.09015019018511343
TEST LOSS at 10-th epoch: 0.06751820735972572
Epoch 11 finished in 283.15 seconds
TRAIN LOSS at 11-th epoch: 0.07346185884500411
VAL LOSS at 11-th epoch: 0.09011437860505611
TEST LOSS at 11-th epoch: 0.06721627312631974
Epoch 12 finished in 282.00 seconds
TRAIN LOSS at 12-th epoch: 0.073157674371736
VAL LOSS at 12-th epoch: 0.09007241276469619
TEST LOSS at 12-th epoch: 0.06697400733452441
Epoch 13 finished in 281.91 seconds
TRAIN LOSS at 13-th epoch: 0.07291726033827328
VAL LOSS at 13-th epoch: 0.09002929136961355
TEST LOSS at 13-th epoch: 0.06677210769237416
Epoch 14 finished in 280.52 seconds
TRAIN LOSS at 14-th epoch: 0.07272117903716033
VAL LOSS at 14-th epoch: 0.08998754788503811
TEST LOSS at 14-th epoch: 0.06659992432222553
Epoch 15 finished in 276.85 seconds
TRAIN LOSS at 15-th epoch: 0.0725574629263327
VAL LOSS at 15-th epoch: 0.08994831116620454
TEST LOSS at 15-th epoch: 0.06645080597397039
Epoch 16 finished in 279.21 seconds
TRAIN LOSS at 16-th epoch: 0.0724182624836088
VAL LOSS at 16-th epoch: 0.08991199495795982
TEST LOSS at 16-th epoch: 0.06632021472611141
Epoch 17 finished in 279.90 seconds
TRAIN LOSS at 17-th epoch: 0.0722981724359179
VAL LOSS at 17-th epoch: 0.08987866635823016
TEST LOSS at 17-th epoch: 0.06620486057565261
Epoch 18 finished in 277.25 seconds
TRAIN LOSS at 18-th epoch: 0.07219332339915971
VAL LOSS at 18-th epoch: 0.08984823103431024
TEST LOSS at 18-th epoch: 0.06610225507715989
Epoch 19 finished in 274.48 seconds
TRAIN LOSS at 19-th epoch: 0.07210085633491636
VAL LOSS at 19-th epoch: 0.08982052466354146
TEST LOSS at 19-th epoch: 0.06601045744772609
Epoch 20 finished in 275.42 seconds
TRAIN LOSS at 20-th epoch: 0.07201860261951205
VAL LOSS at 20-th epoch: 0.08979535797038232
TEST LOSS at 20-th epoch: 0.06592791872310028
/pscratch/sd/p/pakmasha/QTCN/baseline/QLSTM_v0_NARMA.py:124: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, ax = plt.subplots()
Epoch 21 finished in 273.95 seconds
TRAIN LOSS at 21-th epoch: 0.07194488096897259
VAL LOSS at 21-th epoch: 0.08977253886771396
TEST LOSS at 21-th epoch: 0.06585338042209626
Epoch 22 finished in 275.09 seconds
TRAIN LOSS at 22-th epoch: 0.07187836386736561
VAL LOSS at 22-th epoch: 0.08975188315749451
TEST LOSS at 22-th epoch: 0.06578580553149949
Epoch 23 finished in 271.89 seconds
TRAIN LOSS at 23-th epoch: 0.07181798685763882
VAL LOSS at 23-th epoch: 0.0897332193775096
TEST LOSS at 23-th epoch: 0.06572432953571099
Epoch 24 finished in 269.99 seconds
TRAIN LOSS at 24-th epoch: 0.07176288509109083
VAL LOSS at 24-th epoch: 0.08971639055910265
TEST LOSS at 24-th epoch: 0.06566822441917561
Epoch 25 finished in 269.38 seconds
TRAIN LOSS at 25-th epoch: 0.0717123477612131
VAL LOSS at 25-th epoch: 0.08970125432977193
TEST LOSS at 25-th epoch: 0.06561687152482887
Epoch 26 finished in 268.96 seconds
TRAIN LOSS at 26-th epoch: 0.07166578466416487
VAL LOSS at 26-th epoch: 0.08968768216366764
TEST LOSS at 26-th epoch: 0.0655697407766727
Epoch 27 finished in 268.05 seconds
TRAIN LOSS at 27-th epoch: 0.07162270122989851
VAL LOSS at 27-th epoch: 0.08967555825215238
TEST LOSS at 27-th epoch: 0.06552637461485794
Epoch 28 finished in 265.39 seconds
TRAIN LOSS at 28-th epoch: 0.0715826796058292
VAL LOSS at 28-th epoch: 0.08966477826788627
TEST LOSS at 28-th epoch: 0.06548637545717076
Epoch 29 finished in 261.84 seconds
TRAIN LOSS at 29-th epoch: 0.07154536413862751
VAL LOSS at 29-th epoch: 0.08965524817064274
TEST LOSS at 29-th epoch: 0.06544939581271357
Saved epoch losses to QLSTM_TS_MODEL_NARMA_1_order_5_batch_32_seed2027/QLSTM_TS_MODEL_NARMA_1_order_5_batch_32_seed2027_NO_1_Epoch_30_losses.csv
Saved final time series to QLSTM_TS_MODEL_NARMA_1_order_5_batch_32_seed2027/QLSTM_TS_MODEL_NARMA_1_order_5_batch_32_seed2027_NO_1_Epoch_30_timeseries.csv
