/pscratch/sd/p/pakmasha/QTCN/baseline/QLSTM_v0_NARMA.py:9: DeprecationWarning: 
Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
but was not found to be installed on your system.
If this would cause problems for you,
please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466
        
  from pandas import DataFrame
Getting NARMA data...
seed: 2025
x_train.shape:  torch.Size([160, 10, 1])
x_val.shape:  torch.Size([34, 10, 1])
x_test.shape:  torch.Size([35, 10, 1])
y.shape: torch.Size([229, 1])
Show the parameters in QLSTM.
Parameter name: cell.input_gate.weights
Parameter shape: torch.Size([5, 6])
Parameter name: cell.forget_gate.weights
Parameter shape: torch.Size([5, 6])
Parameter name: cell.cell_gate.weights
Parameter shape: torch.Size([5, 6])
Parameter name: cell.output_gate.weights
Parameter shape: torch.Size([5, 6])
Parameter name: cell.output_post_processing.weight
Parameter shape: torch.Size([1, 5])
Parameter name: cell.output_post_processing.bias
Parameter shape: torch.Size([1])
Epoch 0 finished in 224.09 seconds
TRAIN LOSS at 0-th epoch: 0.10387699913330391
VAL LOSS at 0-th epoch: 0.1258204668902787
TEST LOSS at 0-th epoch: 0.09581238200351674
Epoch 1 finished in 221.76 seconds
TRAIN LOSS at 1-th epoch: 0.07166543097583508
VAL LOSS at 1-th epoch: 0.1447487253799601
TEST LOSS at 1-th epoch: 0.11297684950274799
Epoch 2 finished in 227.27 seconds
TRAIN LOSS at 2-th epoch: 0.0676160227628077
VAL LOSS at 2-th epoch: 0.13900099433790108
TEST LOSS at 2-th epoch: 0.10879417237946758
Epoch 3 finished in 239.29 seconds
TRAIN LOSS at 3-th epoch: 0.06492840336632315
VAL LOSS at 3-th epoch: 0.13255424140877026
TEST LOSS at 3-th epoch: 0.10396079776961419
Epoch 4 finished in 249.27 seconds
TRAIN LOSS at 4-th epoch: 0.06280281036987496
VAL LOSS at 4-th epoch: 0.12608221488511417
TEST LOSS at 4-th epoch: 0.09907053319688382
Epoch 5 finished in 250.59 seconds
TRAIN LOSS at 5-th epoch: 0.06102522761003526
VAL LOSS at 5-th epoch: 0.11997122120607283
TEST LOSS at 5-th epoch: 0.094463923327273
Epoch 6 finished in 254.55 seconds
TRAIN LOSS at 6-th epoch: 0.0595143630801656
VAL LOSS at 6-th epoch: 0.11435998614841213
TEST LOSS at 6-th epoch: 0.09027838700063615
Epoch 7 finished in 257.26 seconds
TRAIN LOSS at 7-th epoch: 0.05822036823806531
VAL LOSS at 7-th epoch: 0.10925327817256919
TEST LOSS at 7-th epoch: 0.08652683916234882
Epoch 8 finished in 261.02 seconds
TRAIN LOSS at 8-th epoch: 0.05711137786423291
VAL LOSS at 8-th epoch: 0.1046512305769821
TEST LOSS at 8-th epoch: 0.0832054527006391
Epoch 9 finished in 264.79 seconds
TRAIN LOSS at 9-th epoch: 0.056168341185785155
VAL LOSS at 9-th epoch: 0.10056887645859398
TEST LOSS at 9-th epoch: 0.08031605876552915
Epoch 10 finished in 266.05 seconds
TRAIN LOSS at 10-th epoch: 0.05537702953053547
VAL LOSS at 10-th epoch: 0.09701251978610381
TEST LOSS at 10-th epoch: 0.07785183877336502
Epoch 11 finished in 265.78 seconds
TRAIN LOSS at 11-th epoch: 0.054722104503833954
VAL LOSS at 11-th epoch: 0.09396215239242112
TEST LOSS at 11-th epoch: 0.07578662183731066
Epoch 12 finished in 267.29 seconds
TRAIN LOSS at 12-th epoch: 0.05418610022239136
VAL LOSS at 12-th epoch: 0.09137944998390807
TEST LOSS at 12-th epoch: 0.07408008803439327
Epoch 13 finished in 268.87 seconds
TRAIN LOSS at 13-th epoch: 0.05374973698772627
VAL LOSS at 13-th epoch: 0.08920310228058301
TEST LOSS at 13-th epoch: 0.07268119306356667
Epoch 14 finished in 268.31 seconds
TRAIN LOSS at 14-th epoch: 0.053396435446271796
VAL LOSS at 14-th epoch: 0.08737752736250604
TEST LOSS at 14-th epoch: 0.07153911622855053
Epoch 15 finished in 268.47 seconds
TRAIN LOSS at 15-th epoch: 0.0531037109458942
VAL LOSS at 15-th epoch: 0.08583228673164305
TEST LOSS at 15-th epoch: 0.07059768511822075
Epoch 16 finished in 268.53 seconds
TRAIN LOSS at 16-th epoch: 0.0528636329859453
VAL LOSS at 16-th epoch: 0.08452851540677064
TEST LOSS at 16-th epoch: 0.06982434074693744
Epoch 17 finished in 267.19 seconds
TRAIN LOSS at 17-th epoch: 0.05266446974995002
VAL LOSS at 17-th epoch: 0.0834198052290905
TEST LOSS at 17-th epoch: 0.0691837078695588
Epoch 18 finished in 267.13 seconds
TRAIN LOSS at 18-th epoch: 0.05249701094951158
VAL LOSS at 18-th epoch: 0.08247297952501803
TEST LOSS at 18-th epoch: 0.06864952145741213
Epoch 19 finished in 264.85 seconds
TRAIN LOSS at 19-th epoch: 0.05235486162339041
VAL LOSS at 19-th epoch: 0.08165918703014131
TEST LOSS at 19-th epoch: 0.06820035777500287
Epoch 20 finished in 265.51 seconds
TRAIN LOSS at 20-th epoch: 0.052232677401962246
VAL LOSS at 20-th epoch: 0.08095648122371504
TEST LOSS at 20-th epoch: 0.06781988337312657
/pscratch/sd/p/pakmasha/QTCN/baseline/QLSTM_v0_NARMA.py:124: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, ax = plt.subplots()
Epoch 21 finished in 265.22 seconds
TRAIN LOSS at 21-th epoch: 0.05212662267511664
VAL LOSS at 21-th epoch: 0.08034643809234841
TEST LOSS at 21-th epoch: 0.0674951247878122
Epoch 22 finished in 262.64 seconds
TRAIN LOSS at 22-th epoch: 0.05203352004956112
VAL LOSS at 22-th epoch: 0.07981460082354405
TEST LOSS at 22-th epoch: 0.06721602150442987
Epoch 23 finished in 260.26 seconds
TRAIN LOSS at 23-th epoch: 0.051951153709450915
VAL LOSS at 23-th epoch: 0.07934859159724633
TEST LOSS at 23-th epoch: 0.06697438729238207
Epoch 24 finished in 259.89 seconds
TRAIN LOSS at 24-th epoch: 0.051877559190916675
VAL LOSS at 24-th epoch: 0.07893860879010174
TEST LOSS at 24-th epoch: 0.06676379443254464
Epoch 25 finished in 263.01 seconds
TRAIN LOSS at 25-th epoch: 0.05181147513908467
VAL LOSS at 25-th epoch: 0.07857602706962989
TEST LOSS at 25-th epoch: 0.06657885601823244
Epoch 26 finished in 258.35 seconds
TRAIN LOSS at 26-th epoch: 0.051751566095838177
VAL LOSS at 26-th epoch: 0.07825415800998878
TEST LOSS at 26-th epoch: 0.06641539605292415
Epoch 27 finished in 256.02 seconds
TRAIN LOSS at 27-th epoch: 0.05169715032018903
VAL LOSS at 27-th epoch: 0.07796685071136507
TEST LOSS at 27-th epoch: 0.06626978534517651
Epoch 28 finished in 263.91 seconds
TRAIN LOSS at 28-th epoch: 0.051647200696100716
VAL LOSS at 28-th epoch: 0.07770958607403336
TEST LOSS at 28-th epoch: 0.06613931832006802
Epoch 29 finished in 249.33 seconds
TRAIN LOSS at 29-th epoch: 0.051601438948044996
VAL LOSS at 29-th epoch: 0.07747782804251487
TEST LOSS at 29-th epoch: 0.06602148323433724
Epoch 30 finished in 248.73 seconds
TRAIN LOSS at 30-th epoch: 0.051558954930622916
VAL LOSS at 30-th epoch: 0.07726863039214286
TEST LOSS at 30-th epoch: 0.06591455577667449
Epoch 31 finished in 246.63 seconds
TRAIN LOSS at 31-th epoch: 0.051519806849031666
VAL LOSS at 31-th epoch: 0.0770784090527771
TEST LOSS at 31-th epoch: 0.06581671358193952
Epoch 32 finished in 247.46 seconds
TRAIN LOSS at 32-th epoch: 0.05148304869873036
VAL LOSS at 32-th epoch: 0.07690556218348754
TEST LOSS at 32-th epoch: 0.0657269300417917
Epoch 33 finished in 245.32 seconds
TRAIN LOSS at 33-th epoch: 0.0514491136739022
VAL LOSS at 33-th epoch: 0.0767466361891697
TEST LOSS at 33-th epoch: 0.06564372669639607
