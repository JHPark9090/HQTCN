{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58b2f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "\n",
    "# Saving\n",
    "import pickle\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8516e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def generate_narma_data(n_samples, order, seed=None):\n",
    "    \"\"\"\n",
    "    Generates NARMA time-series data.\n",
    "    \"\"\"\n",
    "    # Fix the random seed for reproducibility\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    u = np.random.uniform(0, 0.5, n_samples)\n",
    "    y = np.zeros(n_samples)\n",
    "\n",
    "    for t in range(order, n_samples):\n",
    "        term1 = 0.3 * y[t-1]\n",
    "        term2 = 0.05 * y[t-1] * np.sum(y[t-i-1] for i in range(order))\n",
    "        term3 = 1.5 * u[t-order] * u[t-1]\n",
    "        term4 = 0.1\n",
    "        y[t] = term1 + term2 + term3 + term4\n",
    "        \n",
    "    return y.reshape(-1, 1)\n",
    "\n",
    "def transform_narma_data(data, seq_length):\n",
    "    \"\"\"\n",
    "    Transforms NARMA data into input-output pairs for sequence prediction.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data) - seq_length - 1):\n",
    "        _x = data[i:(i + seq_length)]\n",
    "        _y = data[i + seq_length]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    x = torch.from_numpy(np.array(x)).float()\n",
    "    y = torch.from_numpy(np.array(y)).float()\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def get_narma_data(n_samples=240, order=10, seq_length=10, seed=None):\n",
    "    \"\"\"\n",
    "    Generates and transforms NARMA data for the QLSTM model.\n",
    "    \"\"\"\n",
    "    seed = seed\n",
    "    print(f\"seed: {seed}\")\n",
    "\n",
    "    # Generate NARMA data\n",
    "    narma_series = generate_narma_data(n_samples, order, seed=seed)\n",
    "\n",
    "    # Normalize the dataset\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    dataset = scaler.fit_transform(narma_series)\n",
    "\n",
    "    # Transform data into sequences\n",
    "    x, y = transform_narma_data(dataset, seq_length)\n",
    "    \n",
    "    return x, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35abcf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: None\n",
      "Shape of X data: torch.Size([229, 10, 1])\n",
      "Shape of Y data: torch.Size([229, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_995575/2578747515.py:18: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  term2 = 0.05 * y[t-1] * np.sum(y[t-i-1] for i in range(order))\n"
     ]
    }
   ],
   "source": [
    "x_data, y_data = get_narma_data()\n",
    "print(\"Shape of X data:\", x_data.shape)\n",
    "print(\"Shape of Y data:\", y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b8d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "dtype = torch.DoubleTensor\n",
    "\n",
    "# x, y = get_narma_data(seq_length=10)\n",
    "print(\"Getting NARMA data...\")\n",
    "x, y = get_narma_data(n_samples=240, seq_length=10, seed=2025)\n",
    "\n",
    "# num_for_train_set = int(0.67 * len(x))\n",
    "\n",
    "# x_train = x[:num_for_train_set].type(dtype)\n",
    "# y_train = y[:num_for_train_set].type(dtype)\n",
    "\n",
    "# x_test = x[num_for_train_set:].type(dtype)\n",
    "# y_test = y[num_for_train_set:].type(dtype)\n",
    "\n",
    "# Split data into training, validation, and testing sets (70%, 15%, 15%)\n",
    "train_end_idx = int(0.70 * len(x))\n",
    "val_end_idx = int(0.85 * len(x)) # 70% + 15%\n",
    "\n",
    "x_train = x[:train_end_idx].type(dtype)\n",
    "y_train = y[:train_end_idx].type(dtype)\n",
    "\n",
    "x_val = x[train_end_idx:val_end_idx].type(dtype)\n",
    "y_val = y[train_end_idx:val_end_idx].type(dtype)\n",
    "\n",
    "x_test = x[val_end_idx:].type(dtype)\n",
    "y_test = y[val_end_idx:].type(dtype)\n",
    "\n",
    "print(\"x_train.shape: \", x_train.shape)\n",
    "print(\"x_val.shape: \", x_val.shape)\n",
    "print(\"x_test.shape: \", x_test.shape)\n",
    "print(\"y.shape: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a61f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check the trainable parameters\n",
    "print(\"Show the parameters in QLSTM.\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}\")\n",
    "        print(f\"Parameter shape: {param.shape}\")\n",
    "        # print(f\"Parameter grad: {param.grad}\")\n",
    "        # print(f\"Parameter value: {param.data}\\n\")\n",
    "\n",
    "##\n",
    "\n",
    "exp_name = \"QLSTM_TS_MODEL_NARMA_1_order_5_batch_32\"\n",
    "exp_index = 1\n",
    "train_len = len(x_train)\n",
    "\n",
    "\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "\n",
    "train_loss_for_all_epoch = []\n",
    "val_loss_for_all_epoch = [] \n",
    "test_loss_for_all_epoch = []\n",
    "iteration_list = []\n",
    "\n",
    "for i in range(50):\n",
    "    start_epoch_time = time.time() # Start timer\n",
    "\n",
    "    iteration_list.append(i + 1)\n",
    "    train_loss_epoch = train_epoch_full(opt = opt, model = model, X = x_train, Y = y_train, batch_size = 32)\n",
    "\n",
    "    # Calculate validation loss\n",
    "    val_loss = nn.MSELoss()\n",
    "    model_res_val, _ = model(x_val)\n",
    "    val_loss_val = val_loss(model_res_val.transpose(0,1)[-1], y_val).detach().numpy()\n",
    "\n",
    "    # Calculate test loss\n",
    "    test_loss = nn.MSELoss()\n",
    "    model_res_test, _ = model(x_test)\n",
    "    test_loss_val = test_loss(model_res_test.transpose(0,1)[-1], y_test).detach().numpy() # 2024 11 11: .transpose(0,1)\n",
    "\n",
    "    end_epoch_time = time.time() # End timer\n",
    "    epoch_duration = end_epoch_time - start_epoch_time\n",
    "\n",
    "    print(\"Epoch {} finished in {:.2f} seconds\".format(i, epoch_duration))\n",
    "    print(\"TRAIN LOSS at {}-th epoch: {}\".format(i, train_loss_epoch))\n",
    "    print(\"VAL LOSS at {}-th epoch: {}\".format(i, val_loss_val))\n",
    "    print(\"TEST LOSS at {}-th epoch: {}\".format(i, test_loss_val))\n",
    "\n",
    "    train_loss_for_all_epoch.append(train_loss_epoch)\n",
    "    val_loss_for_all_epoch.append(val_loss_val)\n",
    "    test_loss_for_all_epoch.append(test_loss_val)\n",
    "\n",
    "    # Run the test\n",
    "    test_run_res, _ = model(x.type(dtype))\n",
    "    total_res = test_run_res.transpose(0,1)[-1].detach().cpu().numpy() # 2024 11 11: .transpose(0,1)\n",
    "    ground_truth_y = y.clone().detach().cpu()\n",
    "\n",
    "    saving(\n",
    "            exp_name = exp_name, \n",
    "            exp_index = exp_index, \n",
    "            train_len = train_len, \n",
    "            val_end_idx = val_end_idx,  \n",
    "            iteration_list = iteration_list, \n",
    "            train_loss_list = train_loss_for_all_epoch, \n",
    "            val_loss_list = val_loss_for_all_epoch,\n",
    "            test_loss_list = test_loss_for_all_epoch, \n",
    "            model = model, \n",
    "            simulation_result = total_res, \n",
    "            ground_truth = ground_truth_y)\n",
    "    \n",
    "# --- CSV LOGGING ---\n",
    "# Prepare data for CSV files\n",
    "file_name_prefix = exp_name + \"_NO_\" + str(exp_index) + \"_Epoch_\" + str(iteration_list[-1])\n",
    "\n",
    "epoch_log_data = {\n",
    "    'epoch': iteration_list,\n",
    "    'train_loss': train_loss_for_all_epoch,\n",
    "    'validation_loss': val_loss_for_all_epoch,\n",
    "    'test_loss': test_loss_for_all_epoch\n",
    "}\n",
    "\n",
    "timeseries_log_data = {\n",
    "    'prediction': total_res.flatten(),\n",
    "    'ground_truth': ground_truth_y.numpy().flatten()\n",
    "}\n",
    "\n",
    "save_log_to_csv(exp_name, file_name_prefix, epoch_log_data, timeseries_log_data)\n",
    "\n",
    "return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
