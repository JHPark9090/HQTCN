{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3567ec6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pennylane Version : 0.41.1\n",
      "Pytorch Version : 2.7.1+cu126\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import copy\n",
    "import time\n",
    "from typing import Any, Optional, Tuple, Callable\n",
    "import mne\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "print('Pennylane Version :', qml.__version__)\n",
    "print('Pytorch Version :', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb6b41cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(\"Running on \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987abe90",
   "metadata": {},
   "source": [
    "# Prepare PhysioNet EEG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2703183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eeg_ts(seed, device, batch_size, sampling_freq):\n",
    "    # Set random seed for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        \n",
    "    # Load and preprocess the PhysioNet EEG Motor Imagery data\n",
    "    N_SUBJECT = 50\n",
    "    IMAGINE_OPEN_CLOSE_LEFT_RIGHT_FIST = [4, 8, 12]\n",
    "\n",
    "    # Load data from PhysioNet (example assumes data is downloaded locally)\n",
    "    physionet_paths = [\n",
    "        mne.datasets.eegbci.load_data(\n",
    "            subjects=subj_id,\n",
    "            runs=IMAGINE_OPEN_CLOSE_LEFT_RIGHT_FIST,\n",
    "            path=\"PhysioNet_EEG\",\n",
    "        ) for subj_id in range(1, N_SUBJECT+1)\n",
    "    ]\n",
    "    physionet_paths = np.concatenate(physionet_paths)\n",
    "\n",
    "    # Ensuring that all subjects share same sampling frequency\n",
    "    # TARGET_SFREQ = 160  # 160 Hz sampling rate\n",
    "    TARGET_SFREQ = sampling_freq\n",
    "\n",
    "    # Concatenate all loaded raw data\n",
    "    parts = []\n",
    "    for path in physionet_paths:\n",
    "        raw = mne.io.read_raw_edf(\n",
    "            path,\n",
    "            preload=True,\n",
    "            stim_channel='auto',\n",
    "            verbose='WARNING',\n",
    "        )\n",
    "        # Resample raw data to ensure consistent sfreq\n",
    "        raw.resample(TARGET_SFREQ, npad=\"auto\")\n",
    "        parts.append(raw)\n",
    "        \n",
    "    # Concatenate resampled raw data\n",
    "    raw = mne.concatenate_raws(parts)\n",
    "\n",
    "    # Pick EEG channels and extract events\n",
    "    eeg_channel_inds = mne.pick_types(\n",
    "        raw.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads'\n",
    "    )\n",
    "    events, _ = mne.events_from_annotations(raw)\n",
    "\n",
    "    # Epoch the data\n",
    "    epoched = mne.Epochs(\n",
    "        raw, events, dict(left=2, right=3), tmin=1, tmax=4.1,\n",
    "        proj=False, picks=eeg_channel_inds, baseline=None, preload=True\n",
    "    )\n",
    "\n",
    "    # Convert data to NumPy arrays\n",
    "    X = (epoched.get_data() * 1e3).astype(np.float32)  # Convert to millivolts\n",
    "    y = (epoched.events[:, 2] - 2).astype(np.int64)  # 0: left, 1: right\n",
    "    \n",
    "    # Train-validation-test split\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=seed)\n",
    "    \n",
    "    def MakeTensorDataset(X, y):\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "        tensordataset = TensorDataset(X_tensor, y_tensor)\n",
    "        return tensordataset\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = MakeTensorDataset(X_train, y_train)\n",
    "    val_dataset = MakeTensorDataset(X_val, y_val)\n",
    "    test_dataset = MakeTensorDataset(X_test, y_test)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    input_dim = X_train.shape\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e8baf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "2250 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 2250 events and 13 original time points ...\n",
      "116 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, input_dim = load_eeg_ts(seed=2025, device=device, batch_size=32, sampling_freq=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac4e4bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-9.3418e-03, -2.0892e-02, -2.5427e-02,  ...,  1.9003e-02,\n",
       "            1.0521e-02,  6.7763e-03],\n",
       "          [-1.8186e-02, -2.4984e-02, -3.0667e-02,  ...,  2.5125e-02,\n",
       "            1.6405e-02,  2.9495e-02],\n",
       "          [-1.0434e-02, -1.6612e-02, -2.2492e-02,  ...,  2.6761e-02,\n",
       "            1.4599e-02,  2.1806e-02],\n",
       "          ...,\n",
       "          [ 1.9377e-03,  1.8254e-03,  5.9484e-03,  ..., -3.2511e-03,\n",
       "           -1.0333e-02,  4.2859e-03],\n",
       "          [-3.2623e-03, -1.1324e-02, -1.3641e-02,  ...,  1.9414e-02,\n",
       "            1.0725e-02,  1.4776e-02],\n",
       "          [ 2.0441e-03,  1.9807e-03, -2.6451e-03,  ...,  5.6664e-03,\n",
       "           -1.1818e-02,  2.9063e-03]],\n",
       " \n",
       "         [[-2.8618e-04,  9.8959e-03, -9.4629e-03,  ...,  4.9505e-03,\n",
       "            5.0498e-03, -8.0845e-03],\n",
       "          [ 1.4872e-03,  1.1819e-02, -7.5468e-03,  ...,  6.8991e-03,\n",
       "            7.0454e-03, -6.1632e-03],\n",
       "          [ 6.6202e-03,  1.6407e-02, -1.0013e-02,  ...,  2.6930e-03,\n",
       "            1.9717e-03,  2.0611e-03],\n",
       "          ...,\n",
       "          [ 4.4995e-04,  3.3664e-03, -1.2076e-02,  ..., -8.1406e-04,\n",
       "           -1.5770e-03, -3.6688e-03],\n",
       "          [-2.6629e-03,  1.0808e-03, -1.4658e-02,  ..., -2.7963e-03,\n",
       "           -7.8586e-03, -8.9051e-03],\n",
       "          [-1.6072e-03, -5.7418e-04, -9.4292e-03,  ..., -2.4930e-03,\n",
       "           -8.9637e-03, -9.9609e-03]],\n",
       " \n",
       "         [[-2.2185e-02, -8.8489e-03, -5.4808e-03,  ...,  2.9668e-03,\n",
       "           -4.7535e-03, -6.2810e-03],\n",
       "          [-2.5703e-02, -8.5777e-03,  9.3798e-04,  ...,  5.4051e-03,\n",
       "            2.2806e-03, -1.9484e-03],\n",
       "          [-2.4373e-02, -5.3008e-03,  1.4238e-03,  ..., -5.1940e-03,\n",
       "            3.6189e-03,  5.9057e-03],\n",
       "          ...,\n",
       "          [-1.8841e-02, -8.1783e-03,  6.2999e-03,  ..., -4.5011e-03,\n",
       "           -4.4381e-03,  9.4727e-03],\n",
       "          [-2.2280e-02, -1.8731e-03, -1.1088e-01,  ..., -2.1031e-03,\n",
       "            6.8663e-03,  2.2586e-02],\n",
       "          [-2.3574e-02,  1.6625e-03, -5.5500e-03,  ..., -7.3751e-03,\n",
       "            1.0649e-02, -9.6262e-04]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.9018e-02,  1.5387e-02, -1.1051e-02,  ...,  1.0820e-02,\n",
       "           -1.1412e-02, -1.3536e-02],\n",
       "          [-2.5560e-02,  1.6703e-02, -1.8278e-02,  ...,  1.2196e-02,\n",
       "           -1.8980e-02, -1.0760e-02],\n",
       "          [-1.4379e-02,  2.1665e-02, -1.0493e-02,  ...,  1.3688e-02,\n",
       "           -1.4408e-02,  1.5181e-02],\n",
       "          ...,\n",
       "          [ 7.5046e-03,  6.5506e-03,  4.3862e-04,  ...,  2.1232e-04,\n",
       "           -2.6273e-02,  8.1750e-03],\n",
       "          [-3.8080e-03,  1.7742e-02, -1.6602e-04,  ...,  1.2323e-02,\n",
       "           -2.1603e-02,  2.3209e-02],\n",
       "          [-1.3315e-02,  2.9468e-03,  7.2239e-05,  ..., -8.7712e-03,\n",
       "           -2.2110e-02, -4.2432e-04]],\n",
       " \n",
       "         [[ 3.5375e-03, -6.1622e-03, -4.2176e-03,  ...,  2.2563e-03,\n",
       "           -7.3277e-03, -3.5795e-03],\n",
       "          [ 4.6634e-03,  6.1442e-04, -3.3509e-05,  ...,  4.3986e-03,\n",
       "           -5.4725e-03, -5.8773e-03],\n",
       "          [-1.7648e-03,  3.2165e-03,  4.0052e-03,  ...,  8.9529e-03,\n",
       "            1.3949e-03, -8.7628e-04],\n",
       "          ...,\n",
       "          [ 1.4833e-03,  1.1467e-02,  1.0112e-02,  ...,  1.4118e-02,\n",
       "           -1.1766e-02, -6.3280e-03],\n",
       "          [-9.7798e-03,  5.3391e-03,  3.0483e-03,  ...,  1.9832e-02,\n",
       "           -1.7459e-02, -1.6459e-02],\n",
       "          [-2.6440e-04,  9.8492e-03,  8.4366e-03,  ...,  1.2855e-02,\n",
       "           -1.3125e-02, -7.7137e-03]],\n",
       " \n",
       "         [[-1.5453e-02, -4.2899e-03, -6.0636e-04,  ...,  1.2326e-02,\n",
       "            8.0616e-03, -2.5558e-04],\n",
       "          [-1.1436e-02, -5.6352e-03, -1.5707e-03,  ...,  9.3839e-03,\n",
       "            5.0539e-03,  7.9465e-04],\n",
       "          [-4.5200e-03,  3.4258e-04,  2.1020e-03,  ...,  8.4158e-03,\n",
       "            4.9464e-03,  1.9540e-03],\n",
       "          ...,\n",
       "          [-1.4860e-02, -7.0937e-03, -6.0509e-03,  ...,  1.4223e-03,\n",
       "            2.7047e-03,  7.9502e-03],\n",
       "          [-1.0398e-02, -2.0068e-03, -1.3884e-03,  ...,  1.5694e-03,\n",
       "            5.3603e-04,  3.9915e-03],\n",
       "          [-1.0451e-02, -4.0358e-03, -4.8117e-03,  ...,  3.8085e-03,\n",
       "            3.7025e-03,  1.0355e-02]]], device='cuda:0'),\n",
       " tensor([0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "         1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "467a7976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1493, 64, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "929b01a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcn import TemporalConvNet\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EEGTCNClassifier(nn.Module):\n",
    "    def __init__(self, in_ch, tcn_ch, num_classes, k=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.tcn = TemporalConvNet(in_ch, tcn_ch, k, dropout)\n",
    "        self.linear = nn.Linear(tcn_ch[-1], num_classes)\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, L)\n",
    "        y = self.tcn(x)            # → (B, C_out, L)\n",
    "        logit = self.linear(y[:, :, -1])\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63f80bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Calculate Running Time ########################################\n",
    "def epoch_time(start_time: float, end_time: float) -> Tuple[float, float]:\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n",
    "################################# Performance & Density Matrices ################################\n",
    "# Training loop\n",
    "def train_perf(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    for inputs, labels in tqdm(dataloader):\n",
    "        assert not torch.isnan(inputs).any(), \"Inputs contain NaN!\"\n",
    "        assert not torch.isinf(inputs).any(), \"Inputs contain Inf!\"\n",
    "        assert not torch.isnan(labels).any(), \"Labels contain NaN!\"\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Ensure that data is on the same device (GPU or CPU)\n",
    "        labels = labels.float()   # Ensure labels are of type float for BCEWithLogitsLoss\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Collect labels and outputs for AUROC\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_outputs.append(outputs.detach().cpu().numpy())       \n",
    "    # Calculate train AUROC\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    print(\"labels NaNs:\", np.isnan(all_labels).sum(), \"/\", all_labels.shape[0])\n",
    "    print(\"outputs NaNs:\", np.isnan(all_outputs).sum(), \"/\", all_outputs.shape[0])\n",
    "    train_auroc = roc_auc_score(all_labels, all_outputs)\n",
    "    \n",
    "    return train_loss / len(dataloader), train_auroc\n",
    "\n",
    "\n",
    "# Validation/Test loop\n",
    "def evaluate_perf(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Ensure that data is on the same device (GPU or CPU)\n",
    "            labels = labels.float()   # Ensure labels are of type float for BCEWithLogitsLoss\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Collect labels and outputs for AUROC\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    auroc = roc_auc_score(all_labels, all_outputs)\n",
    "    \n",
    "    return running_loss / len(dataloader), auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5fd8c387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/a/alveare/.conda/envs/qml/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      " 32%|███▏      | 15/47 [00:00<00:00, 142.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 150.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 461.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 0s\n",
      "Train Loss: 0.6938, AUC: 0.4821 | Validation Loss: 0.6921, AUC: 0.6155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 155.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 442.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 0s\n",
      "Train Loss: 0.6899, AUC: 0.5609 | Validation Loss: 0.6892, AUC: 0.6330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 142.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 480.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 0s\n",
      "Train Loss: 0.6664, AUC: 0.6529 | Validation Loss: 0.6381, AUC: 0.7458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 136.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 365.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 0s\n",
      "Train Loss: 0.6149, AUC: 0.7297 | Validation Loss: 0.6070, AUC: 0.7530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 149.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 365.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 0s\n",
      "Train Loss: 0.5778, AUC: 0.7761 | Validation Loss: 0.6118, AUC: 0.7523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 129.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 276.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 0s\n",
      "Train Loss: 0.5578, AUC: 0.7940 | Validation Loss: 0.5926, AUC: 0.7654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 113.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 321.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 0s\n",
      "Train Loss: 0.5507, AUC: 0.7940 | Validation Loss: 0.5927, AUC: 0.7615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 113.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 325.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 0s\n",
      "Train Loss: 0.5227, AUC: 0.8197 | Validation Loss: 0.5907, AUC: 0.7632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 119.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 398.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 0s\n",
      "Train Loss: 0.5137, AUC: 0.8262 | Validation Loss: 0.5962, AUC: 0.7657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 140.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 427.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 0s\n",
      "Train Loss: 0.5035, AUC: 0.8338 | Validation Loss: 0.6153, AUC: 0.7651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 159.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 440.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 0m 0s\n",
      "Train Loss: 0.4889, AUC: 0.8449 | Validation Loss: 0.5756, AUC: 0.7816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 154.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 387.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 0m 0s\n",
      "Train Loss: 0.4688, AUC: 0.8589 | Validation Loss: 0.6116, AUC: 0.7643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 137.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 385.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 0m 0s\n",
      "Train Loss: 0.4682, AUC: 0.8604 | Validation Loss: 0.6044, AUC: 0.7727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 140.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 420.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 0m 0s\n",
      "Train Loss: 0.4563, AUC: 0.8667 | Validation Loss: 0.6131, AUC: 0.7750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 140.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 372.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 0m 0s\n",
      "Train Loss: 0.4777, AUC: 0.8521 | Validation Loss: 0.5999, AUC: 0.7715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 143.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 414.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 0m 0s\n",
      "Train Loss: 0.4457, AUC: 0.8745 | Validation Loss: 0.6261, AUC: 0.7779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 152.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 446.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 0m 0s\n",
      "Train Loss: 0.4442, AUC: 0.8743 | Validation Loss: 0.6161, AUC: 0.7678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 146.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 409.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 0m 0s\n",
      "Train Loss: 0.4312, AUC: 0.8827 | Validation Loss: 0.6315, AUC: 0.7714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 146.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 420.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 0m 0s\n",
      "Train Loss: 0.4316, AUC: 0.8830 | Validation Loss: 0.6272, AUC: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 135.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels NaNs: 0 / 1493\n",
      "outputs NaNs: 0 / 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 380.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 0m 0s\n",
      "Train Loss: 0.4135, AUC: 0.8931 | Validation Loss: 0.6320, AUC: 0.7743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 392.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5062, AUC: 0.8192\n",
      "Metrics saved to TCN_performance.csv\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20  # Set the number of epochs for training\n",
    "\n",
    "model = EEGTCNClassifier(in_ch=64, tcn_ch=[64, 64, 64], num_classes=1, k=2, dropout=0.2).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()  # Use BCEWithLogitsLoss for binary classification\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-4, eps=1e-8)\n",
    "\n",
    "# Training process\n",
    "train_metrics, valid_metrics, test_metrics = [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_auc = train_perf(model, train_loader, optimizer, criterion)\n",
    "    train_metrics.append({'epoch': epoch + 1, 'train_loss': train_loss, 'train_auc': train_auc})    \n",
    "\n",
    "    valid_loss, valid_auc = evaluate_perf(model, val_loader, criterion)\n",
    "    valid_metrics.append({'epoch': epoch + 1, 'valid_loss': valid_loss, 'valid_auc': valid_auc})\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f\"Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, AUC: {train_auc:.4f} | Validation Loss: {valid_loss:.4f}, AUC: {valid_auc:.4f}\")\n",
    "\n",
    "# Final evaluation on the test set\n",
    "test_loss, test_auc = evaluate_perf(model, test_loader, criterion)\n",
    "print(f\"Test Loss: {test_loss:.4f}, AUC: {test_auc:.4f}\")\n",
    "test_metrics.append({'epoch': num_epochs, 'test_loss': test_loss, 'test_auc': test_auc}) \n",
    "\n",
    "# Combine all metrics into a pandas DataFrame\n",
    "metrics = []\n",
    "for epoch in range(num_epochs):\n",
    "    metrics.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': train_metrics[epoch]['train_loss'],\n",
    "        'train_auc': train_metrics[epoch]['train_auc'],\n",
    "        'valid_loss': valid_metrics[epoch]['valid_loss'],\n",
    "        'valid_auc': valid_metrics[epoch]['valid_auc'],\n",
    "        'test_loss': test_metrics[0]['test_loss'],\n",
    "        'test_auc': test_metrics[0]['test_auc'],\n",
    "    })\n",
    "# Convert to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "# Save to CSV\n",
    "csv_filename = f\"TCN_performance.csv\"\n",
    "metrics_df.to_csv(csv_filename, index=False)\n",
    "print(f\"Metrics saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e61d4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
