{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf1ecb8-6ad7-428b-a9f5-4237132c3f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/j/junghoon/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pennylane/capture/capture_operators.py:33: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.4.28. You have version 0.4.34 installed. Please downgrade JAX to <=0.4.28 to avoid runtime errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on  cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import copy\n",
    "import time\n",
    "from typing import Any, Optional, Tuple, Callable\n",
    "import mne\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(\"Running on \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7feaffb4-95a9-4602-b5bf-814694e02e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eeg_ts(seed, device, batch_size, sampling_freq):\n",
    "    # Set random seed for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        \n",
    "    # Load and preprocess the PhysioNet EEG Motor Imagery data\n",
    "    N_SUBJECT = 50\n",
    "    IMAGINE_OPEN_CLOSE_LEFT_RIGHT_FIST = [4, 8, 12]\n",
    "\n",
    "    # Load data from PhysioNet (example assumes data is downloaded locally)\n",
    "    physionet_paths = [\n",
    "        mne.datasets.eegbci.load_data(\n",
    "            subjects=subj_id,\n",
    "            runs=IMAGINE_OPEN_CLOSE_LEFT_RIGHT_FIST,\n",
    "            path=\"PhysioNet_EEG\",\n",
    "        ) for subj_id in range(1, N_SUBJECT+1)\n",
    "    ]\n",
    "    physionet_paths = np.concatenate(physionet_paths)\n",
    "\n",
    "    # Ensuring that all subjects share same sampling frequency\n",
    "    # TARGET_SFREQ = 160  # 160 Hz sampling rate\n",
    "    TARGET_SFREQ = sampling_freq\n",
    "\n",
    "    # Concatenate all loaded raw data\n",
    "    parts = []\n",
    "    for path in physionet_paths:\n",
    "        raw = mne.io.read_raw_edf(\n",
    "            path,\n",
    "            preload=True,\n",
    "            stim_channel='auto',\n",
    "            verbose='WARNING',\n",
    "        )\n",
    "        # Resample raw data to ensure consistent sfreq\n",
    "        raw.resample(TARGET_SFREQ, npad=\"auto\")\n",
    "        parts.append(raw)\n",
    "        \n",
    "    # Concatenate resampled raw data\n",
    "    raw = mne.concatenate_raws(parts)\n",
    "\n",
    "    # Pick EEG channels and extract events\n",
    "    eeg_channel_inds = mne.pick_types(\n",
    "        raw.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads'\n",
    "    )\n",
    "    events, _ = mne.events_from_annotations(raw)\n",
    "\n",
    "    # Epoch the data\n",
    "    epoched = mne.Epochs(\n",
    "        raw, events, dict(left=2, right=3), tmin=1, tmax=4.1,\n",
    "        proj=False, picks=eeg_channel_inds, baseline=None, preload=True\n",
    "    )\n",
    "\n",
    "    # Convert data to NumPy arrays\n",
    "    X = (epoched.get_data() * 1e3).astype(np.float32)  # Convert to millivolts\n",
    "    y = (epoched.events[:, 2] - 2).astype(np.int64)  # 0: left, 1: right\n",
    "    \n",
    "    # Train-validation-test split\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=seed)\n",
    "    \n",
    "    def MakeTensorDataset(X, y):\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "        tensordataset = TensorDataset(X_tensor, y_tensor)\n",
    "        return tensordataset\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = MakeTensorDataset(X_train, y_train)\n",
    "    val_dataset = MakeTensorDataset(X_val, y_val)\n",
    "    test_dataset = MakeTensorDataset(X_test, y_test)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    input_dim = X_train.shape\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ee3b7c8-8222-4468-b94f-00ec540838eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "2250 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 2250 events and 249 original time points ...\n",
      "116 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, input_dim = load_eeg_ts(seed=2025, device=device, batch_size=32, sampling_freq=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1314b40-12ff-42a0-b8c3-88e576580bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1493, 64, 249)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
