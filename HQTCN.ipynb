{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf1ecb8-6ad7-428b-a9f5-4237132c3f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/j/junghoon/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pennylane/capture/capture_operators.py:33: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.4.28. You have version 0.4.34 installed. Please downgrade JAX to <=0.4.28 to avoid runtime errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on  cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import copy\n",
    "import time\n",
    "from typing import Any, Optional, Tuple, Callable\n",
    "import mne\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(\"Running on \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e42e6b6d-faf1-45c1-b202-c2ac412a5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "    \"\"\"\n",
    "    A module that removes the last 'chomp_size' elements from the last dimension of a tensor.\n",
    "    This is used to implement causal convolutions.\n",
    "    \"\"\"\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, channels, sequence_length)\n",
    "        Returns:\n",
    "            Tensor of shape (batch_size, channels, sequence_length - chomp_size)\n",
    "        \"\"\"\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A single temporal block, which is the building block of the TCN.\n",
    "    It consists of two causal, dilated convolutions with weight normalization,\n",
    "    ReLU activation, and dropout. It also includes a residual connection.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        \n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    \"\"\"\n",
    "    The main Temporal Convolutional Network model.\n",
    "    It consists of a stack of temporal blocks with increasing dilation factors.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b3204ec-cc80-4cdd-ab4d-e8ec14fba1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HQTCN(nn.Module):\n",
    "    def __init__(self, n_qubits, n_layers, num_channels, input_dim, kernel_size, dropout):\n",
    "        \"\"\"\n",
    "        n_qubits (int): Number of qubits for QCNN circuit.\n",
    "        n_layers (int): Number of convolutional & pooling layers for QCNN circuit.\n",
    "        num_channels (list): Number of channels for the classical TCN block. The last component should equal the number of qubits.\n",
    "        input_dim (tuple): Shape of the input data.\n",
    "        kernel_size (int): Kernel size for classical TCN block.\n",
    "        dropout (float): Level of drop out for classical TCN block.\n",
    "        \"\"\"\n",
    "        super(HQTCN, self).__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        # Quantum parameters\n",
    "        self.conv_params = nn.Parameter(torch.randn(n_layers, n_qubits, 15))\n",
    "        self.pool_params = nn.Parameter(torch.randn(n_layers, n_qubits // 2, 3))\n",
    "        # Quantum device initialization\n",
    "        self.dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "        # The kernel size defines how many time steps we consider for the \"convolution\"\n",
    "        self.input_channels = input_dim[1]\n",
    "        # QCNN Circuit\n",
    "        self.qc = qml.QNode(self.circuit, self.dev)\n",
    "        # Classical TCN Block\n",
    "        self.tcn = TemporalConvNet(input_dim[1], num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "\n",
    "    def circuit(self, features):\n",
    "        wires = list(range(self.n_qubits))    \n",
    "        # Variational Embedding (Angle Embedding)\n",
    "        qml.AngleEmbedding(features, wires=wires, rotation='Y')\n",
    "        for layer in range(self.n_layers):\n",
    "            # Convolutional Layer\n",
    "            self._apply_convolution(self.conv_params[layer], wires)\n",
    "            # Pooling Layer\n",
    "            self._apply_pooling(self.pool_params[layer], wires)\n",
    "            wires = wires[::2]  # Retain every second qubit after pooling\n",
    "        # Measurement\n",
    "        return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "    def _apply_convolution(self, weights, wires):\n",
    "        \"\"\"\n",
    "        Convolutional layer logic (same as original).\n",
    "        \"\"\"\n",
    "        n_wires = len(wires)\n",
    "        for p in [0, 1]:\n",
    "            for indx, w in enumerate(wires):\n",
    "                if indx % 2 == p and indx < n_wires - 1:\n",
    "                    qml.U3(*weights[indx, :3], wires=w)\n",
    "                    qml.U3(*weights[indx + 1, 3:6], wires=wires[indx + 1])\n",
    "                    qml.IsingZZ(weights[indx, 6], wires=[w, wires[indx + 1]])\n",
    "                    qml.IsingYY(weights[indx, 7], wires=[w, wires[indx + 1]])\n",
    "                    qml.IsingXX(weights[indx, 8], wires=[w, wires[indx + 1]])\n",
    "                    qml.U3(*weights[indx, 9:12], wires=w)\n",
    "                    qml.U3(*weights[indx + 1, 12:], wires=wires[indx + 1])\n",
    "\n",
    "    def _apply_pooling(self, pool_weights, wires):\n",
    "        # Pooling using a variational circuit\n",
    "        n_wires = len(wires)\n",
    "        assert n_wires >= 2, \"Need at least two wires for pooling.\"\n",
    "\n",
    "        for indx, w in enumerate(wires):\n",
    "            if indx % 2 == 1 and indx < n_wires:\n",
    "                measurement = qml.measure(w)\n",
    "                qml.cond(measurement, qml.U3)(*pool_weights[indx // 2], wires=wires[indx - 1])\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # The input x has shape (batch_size, num_channels, n_timesteps)\n",
    "        y1 = self.tcn(x)\n",
    "        # Global Average Pooling across the time dimension\n",
    "        y2 = torch.mean(y1, dim=2)\n",
    "        # QCNN execution\n",
    "        output = self.qc(y2)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7feaffb4-95a9-4602-b5bf-814694e02e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eeg_ts(seed, device, batch_size, sampling_freq):\n",
    "    # Set random seed for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        \n",
    "    # Load and preprocess the PhysioNet EEG Motor Imagery data\n",
    "    N_SUBJECT = 50\n",
    "    IMAGINE_OPEN_CLOSE_LEFT_RIGHT_FIST = [4, 8, 12]\n",
    "\n",
    "    # Load data from PhysioNet (example assumes data is downloaded locally)\n",
    "    physionet_paths = [\n",
    "        mne.datasets.eegbci.load_data(\n",
    "            subjects=subj_id,\n",
    "            runs=IMAGINE_OPEN_CLOSE_LEFT_RIGHT_FIST,\n",
    "            path=\"PhysioNet_EEG\",\n",
    "        ) for subj_id in range(1, N_SUBJECT+1)\n",
    "    ]\n",
    "    physionet_paths = np.concatenate(physionet_paths)\n",
    "\n",
    "    # Ensuring that all subjects share same sampling frequency\n",
    "    # TARGET_SFREQ = 160  # 160 Hz sampling rate\n",
    "    TARGET_SFREQ = sampling_freq\n",
    "\n",
    "    # Concatenate all loaded raw data\n",
    "    parts = []\n",
    "    for path in physionet_paths:\n",
    "        raw = mne.io.read_raw_edf(\n",
    "            path,\n",
    "            preload=True,\n",
    "            stim_channel='auto',\n",
    "            verbose='WARNING',\n",
    "        )\n",
    "        # Resample raw data to ensure consistent sfreq\n",
    "        raw.resample(TARGET_SFREQ, npad=\"auto\")\n",
    "        parts.append(raw)\n",
    "        \n",
    "    # Concatenate resampled raw data\n",
    "    raw = mne.concatenate_raws(parts)\n",
    "\n",
    "    # Pick EEG channels and extract events\n",
    "    eeg_channel_inds = mne.pick_types(\n",
    "        raw.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads'\n",
    "    )\n",
    "    events, _ = mne.events_from_annotations(raw)\n",
    "\n",
    "    # Epoch the data\n",
    "    epoched = mne.Epochs(\n",
    "        raw, events, dict(left=2, right=3), tmin=1, tmax=4.1,\n",
    "        proj=False, picks=eeg_channel_inds, baseline=None, preload=True\n",
    "    )\n",
    "\n",
    "    # Convert data to NumPy arrays\n",
    "    X = (epoched.get_data() * 1e3).astype(np.float32)  # Convert to millivolts\n",
    "    y = (epoched.events[:, 2] - 2).astype(np.int64)  # 0: left, 1: right\n",
    "    \n",
    "    # Train-validation-test split\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=seed)\n",
    "    \n",
    "    def MakeTensorDataset(X, y):\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "        tensordataset = TensorDataset(X_tensor, y_tensor)\n",
    "        return tensordataset\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = MakeTensorDataset(X_train, y_train)\n",
    "    val_dataset = MakeTensorDataset(X_val, y_val)\n",
    "    test_dataset = MakeTensorDataset(X_test, y_test)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    input_dim = X_train.shape\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31d7976c-0777-4fc2-9c04-746a2b208143",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Calculate Running Time ########################################\n",
    "def epoch_time(start_time: float, end_time: float) -> Tuple[float, float]:\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n",
    "################################# Performance & Density Matrices ################################\n",
    "# Training loop\n",
    "def train_perf(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    for inputs, labels in tqdm(dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Ensure that data is on the same device (GPU or CPU)\n",
    "        labels = labels.float()   # Ensure labels are of type float for BCEWithLogitsLoss\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Collect labels and outputs for AUROC\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_outputs.append(outputs.detach().cpu().numpy())       \n",
    "        \n",
    "    # Calculate train AUROC\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    train_auroc = roc_auc_score(all_labels, all_outputs)\n",
    "    \n",
    "    return train_loss / len(dataloader), train_auroc\n",
    "\n",
    "\n",
    "# Validation/Test loop\n",
    "def evaluate_perf(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Ensure that data is on the same device (GPU or CPU)\n",
    "            labels = labels.float()   # Ensure labels are of type float for BCEWithLogitsLoss\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Collect labels and outputs for AUROC\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    auroc = roc_auc_score(all_labels, all_outputs)\n",
    "    \n",
    "    return running_loss / len(dataloader), auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ee3b7c8-8222-4468-b94f-00ec540838eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Not setting metadata\n",
      "2250 matching events found\n",
      "No baseline correction applied\n",
      "Using data from preloaded Raw for 2250 events and 249 original time points ...\n",
      "116 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, input_dim = load_eeg_ts(seed=2025, device=device, batch_size=32, sampling_freq=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1314b40-12ff-42a0-b8c3-88e576580bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1493, 64, 249)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e27acda0-d658-421a-b51b-682d8e904f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HybridQuantumTCNN_run(n_qubits, n_layers, num_channels, input_dim, kernel_size, dropout, num_epochs):\n",
    "    print(\"Running on \", device)\n",
    "    model = HQTCN(n_qubits, n_layers, num_channels, input_dim, kernel_size, dropout).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()  # Use BCEWithLogitsLoss for binary classification\n",
    "    optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-4, eps=1e-8)\n",
    "        \n",
    "    # Training process\n",
    "    train_metrics, valid_metrics, test_metrics = [], [], []\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss, train_auc = train_perf(model, train_loader, optimizer, criterion)\n",
    "        train_metrics.append({'epoch': epoch + 1, 'train_loss': train_loss, 'train_auc': train_auc})    \n",
    "    \n",
    "        valid_loss, valid_auc = evaluate_perf(model, val_loader, criterion)\n",
    "        valid_metrics.append({'epoch': epoch + 1, 'valid_loss': valid_loss, 'valid_auc': valid_auc})\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        print(f\"Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, AUC: {train_auc:.4f} | Validation Loss: {valid_loss:.4f}, AUC: {valid_auc:.4f}\")\n",
    "\n",
    "    # Final evaluation on the test set\n",
    "    test_loss, test_auc = evaluate_perf(model, test_loader, criterion)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, AUC: {test_auc:.4f}\")\n",
    "    test_metrics.append({'epoch': num_epochs, 'test_loss': test_loss, 'test_auc': test_auc}) \n",
    "\n",
    "    # Combine all metrics into a pandas DataFrame\n",
    "    metrics = []\n",
    "    for epoch in range(num_epochs):\n",
    "        metrics.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_metrics[epoch]['train_loss'],\n",
    "            'train_auc': train_metrics[epoch]['train_auc'],\n",
    "            'valid_loss': valid_metrics[epoch]['valid_loss'],\n",
    "            'valid_auc': valid_metrics[epoch]['valid_auc'],\n",
    "            'test_loss': test_metrics[0]['test_loss'],\n",
    "            'test_auc': test_metrics[0]['test_auc'],\n",
    "        })\n",
    "    # Convert to DataFrame\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    # Save to CSV\n",
    "    csv_filename = f\"HybridQTCN_performance.csv\"\n",
    "    metrics_df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Metrics saved to {csv_filename}\")\n",
    "        \n",
    "    return test_loss, test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30353261-3ed4-447b-8f1e-f1e7eaf7fc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/j/junghoon/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:08<00:00,  5.51it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 15.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 9s\n",
      "Train Loss: 0.6938, AUC: 0.4784 | Validation Loss: 0.6930, AUC: 0.5772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:05<00:00,  8.40it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 6s\n",
      "Train Loss: 0.6923, AUC: 0.5316 | Validation Loss: 0.6916, AUC: 0.6526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:07<00:00,  6.23it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 8s\n",
      "Train Loss: 0.6861, AUC: 0.6342 | Validation Loss: 0.6824, AUC: 0.6628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:08<00:00,  5.65it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 9s\n",
      "Train Loss: 0.6705, AUC: 0.6751 | Validation Loss: 0.6649, AUC: 0.6941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:08<00:00,  5.54it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 9s\n",
      "Train Loss: 0.6459, AUC: 0.7329 | Validation Loss: 0.6490, AUC: 0.7092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 38/47 [00:06<00:01,  5.27it/s]"
     ]
    }
   ],
   "source": [
    "HybridQuantumTCNN_run(n_qubits=8, n_layers=2, num_channels=[64, 8], input_dim=input_dim, kernel_size=2, dropout=0.2, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc09af-f161-4c7c-a2bd-5e682f9f3bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93983403-54ce-4032-a121-438d29fa0108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b61ec9e-5b23-4d8f-9229-a1e49d9cfb66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e19aa-5b8c-4a1d-b78e-b8c050ec1132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc59485-4498-4384-b0c4-21e07d6e71bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
